# Optimized Q&A System with Chainlit & Streamlit | Langchain | Transformers | Qdrant

## Overview
This project presents a robust Q&A application that enables users to interact with PDF documents by uploading files and querying for insights. The system combines Chainlit and Streamlit applications, delivering a powerful interface for document analysis. By leveraging transformer models to generate embeddings, the application efficiently stores vectors in Qdrant, an open-source vector database. Built with Langchain, the Q&A system integrates advanced language models like Phi-2 and Ollama, achieving a 25% improvement in query response times.

## Features
- **PDF Document Interaction**: Users can upload PDF files and ask questions to extract relevant insights quickly and accurately.
- **Optimized Embedding Storage**: Transformer-based embeddings are stored in Qdrant, ensuring fast and efficient data retrieval.
- **Enhanced Query Performance**: Langchain-powered integration with models like Phi-2 and Ollama, improving response times by 25%.
- **User-Friendly UI**: Chainlit and Streamlit provide a streamlined interface for document upload and querying, making it easy to interact with and extract data from PDFs.

## Technical Stack
- **Languages**: Python
- **Libraries**: Chainlit, Streamlit, Langchain, Hugging Face Transformers, Qdrant
- **Models**: Phi-2, Ollama, and other transformer-based models
- **Tools**: Qdrant (vector storage), Chainlit and Streamlit (UI), Langchain (Q&A system)

## Results
- Achieved a 25% reduction in query response times, enhancing efficiency and user experience in document-based Q&A.

